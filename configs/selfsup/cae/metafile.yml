Collections:
  - Name: CAE
    Metadata:
      Training Data: ImageNet-1k
      Training Techniques:
        - AdamW
<<<<<<< HEAD
      Training Resources: 16x A100-80G GPUs
=======
      Training Resources: 8x A100-80G GPUs
>>>>>>> upstream/master
      Architecture:
        - ViT
    Paper:
        URL: https://arxiv.org/abs/2202.03026
        Title: "Context Autoencoder for Self-Supervised Representation Learning"
    README: configs/selfsup/cae/README.md

Models:
  - Name: cae_vit-base-p16_8xb256-fp16-coslr-300e_in1k
    In Collection: CAE
    Metadata:
      Epochs: 300
      Batch Size: 2048
<<<<<<< HEAD
    Results: null
    Config: configs/selfsup/cae/cae_vit-base-p16_16xb128-amp-coslr-300e_in1k.py
    Weights: https://download.openmmlab.com/mmselfsup/1.x/cae/cae_vit-base-p16_16xb128-fp16-coslr-300e_in1k/cae_vit-base-p16_16xb128-fp16-coslr-300e_in1k_20220825-404a1929.pth
    Downstream:
      - Type: Image Classification
        Metadata:
          Epochs: 100
          Batch Size: 1024
        Results:
          - Task: Fine-tuning
            Dataset: ImageNet-1k
            Metrics:
              Top 1 Accuracy: 60.8
        Config: configs/benchmarks/classification/imagenet/vit-base-p16_ft-8xb128-coslr-100e-rpe_in1k.py
        Weights: https://download.openmmlab.com/mmselfsup/1.x/cae/cae_vit-base-p16_16xb128-fp16-coslr-300e_in1k/vit-base-p16_ft-8xb128-coslr-100e-rpe_in1k/vit-base-p16_ft-8xb128-coslr-100e-rpe_in1k_20220825-f3d234cd.pth
=======
    Results:
      - Task: Self-Supervised Image Classification
        Dataset: ImageNet-1k
        Metrics:
          Top 1 Accuracy: 83.2
    Config: configs/selfsup/cae/cae_vit-base-p16_8xb256-fp16-coslr-300e_in1k.py
    Weights: https://download.openmmlab.com/mmselfsup/cae/cae_vit-base-p16_16xb256-coslr-300e_in1k-224_20220427-4c786349.pth
>>>>>>> upstream/master
