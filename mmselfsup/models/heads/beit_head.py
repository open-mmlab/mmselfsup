# Copyright (c) OpenMMLab. All rights reserved.
import os
import warnings
from typing import List, Optional, Tuple, Union

import torch
from mmengine.model import BaseModule
from torch import nn

from mmselfsup.registry import MODELS
from ..utils import VQKD, Encoder


@MODELS.register_module()
class BEiTHead(BaseModule):
    """Pretrain Head for BEiT.

    Compute the cross entropy loss. In addition, this head also
    generates the prediction target generated by dalle.

    Args:
        loss (dict): The config of loss.
        tokenizer_path (str): The path of the tokenizer.
        init_cfg (dict or List[dict], optional): Initialization config dict.
            Defaults to None.
    """

    def __init__(self,
                 loss: dict,
                 tokenizer_type: str,
                 tokenizer_path: str,
                 init_cfg: Optional[Union[dict, List[dict]]] = None) -> None:
        super().__init__(init_cfg=init_cfg)
        self.tokenizer_type = tokenizer_type
        self.tokenizer_path = tokenizer_path
        self.encoder = self._load_encoder()
        self.loss = MODELS.build(loss)

    def _load_encoder(self) -> nn.Module:
        if self.tokenizer_type == 'dall-e':
            encoder = Encoder()
        elif self.tokenizer_type == 'vqkd':
            encoder = VQKD()

        if os.path.exists(self.tokenizer_path):
            state_dict = torch.load(self.tokenizer_path)
            encoder.load_state_dict(state_dict)
        else:
            warnings.warn(
                f'Do not find {self.tokenizer_path}, please download from https://download.openmmlab.com/mmselfsup/cae/dalle_encoder.pth'  # noqa: E501
            )
        return encoder

    @torch.no_grad()
    def _generate_target(self, img_target: torch.Tensor) -> torch.Tensor:
        """Generate the reconstruction target."""
        logits = self.encoder(img_target)
        if self.tokenizer_type == 'dall-e':
            target = torch.argmax(logits, dim=1)
            target = target.flatten(1)
        elif self.tokenizer_type == 'vqkd':
            target = logits
        return target

    def forward(self,
                logits: Union[Tuple[torch.Tensor], torch.Tensor],
                img_target: torch.Tensor,
                mask: torch.Tensor,
                return_all_tokens=False) -> torch.Tensor:
        """Generate loss.

        Args:
            logits (torch.Tensor): Logits generated by decoder.
            img_target (img_target): Target generated by dalle for decoder
                prediction.
        """

        target = self._generate_target(img_target)  # target features
        target = target.detach()

        if not return_all_tokens:
            mask = mask.flatten(0).to(torch.bool)
            target = target.view(-1, 1)
            target = target[mask]
            if isinstance(logits, torch.Tensor):
                logits = logits[mask]
            elif isinstance(logits, Tuple):
                logits = logits[0][mask], logits[1][mask]

        loss = self.loss(logits, target.squeeze(-1))
        return loss
